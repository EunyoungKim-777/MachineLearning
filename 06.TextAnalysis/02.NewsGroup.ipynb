{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b26661d338b6288df508a7ea172ff591d6ed882578e82460ed30bfeb70cfcac3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 20 뉴스 그룹 분류"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\r\n",
    "news_data = fetch_20newsgroups(subset='all',random_state=156)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 데이터 탐색"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "news_data.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "pd.Series(news_data.target).value_counts().sort_index()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     799\n",
       "1     973\n",
       "2     985\n",
       "3     982\n",
       "4     963\n",
       "5     988\n",
       "6     975\n",
       "7     990\n",
       "8     996\n",
       "9     994\n",
       "10    999\n",
       "11    991\n",
       "12    984\n",
       "13    990\n",
       "14    987\n",
       "15    997\n",
       "16    910\n",
       "17    940\n",
       "18    775\n",
       "19    628\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(news_data.data[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 훈련/테스트용 데이터 추출"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_news = fetch_20newsgroups(subset='train', random_state=150, remove=('headers','footers','quotes'))\r\n",
    "X_train = train_news.data\r\n",
    "y_train = train_news.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(train_news.data[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "   >Thousands?  Tens of thousands?  Do some arithmetic, please...  Skipjack\n",
      "   >has 2^80 possible keys.  Let's assume a brute-force engine like that\n",
      "   >hypothesized for DES:  1 microsecond per trial, 1 million chips.  That's\n",
      "   >10^12 trials per second, or about 38,000 years for 2^80 trials.  Well,\n",
      "   >maybe they can get chips running at one trial per nanosecond, and build\n",
      "   >a machine with 10 million chips.  Sure -- only 3.8 years for each solution.\n",
      "\n",
      "   But there is a MUCH more pernicious problem with the scheme as\n",
      "proposed.  Building a brute force machine to test 2^40 possible keys\n",
      "if you have the other half from one escrow agent is EASY.  (One chip,\n",
      "one test per microsecond gives you one break every two weeks, and that\n",
      "break gives you all messages involving that phone.)\n",
      "\n",
      "   The XOR scheme so that the files from one escrow agent gives you\n",
      "nothing is an improvement, but notice that XORing with (truely random)\n",
      "bit strings allows for an arbitrary number of escrow agents.  Using +\n",
      "for XOR, SK for the escrowed key, and A and B for two random bit\n",
      "strings, hand SK+A+B, SK+A, and SK+B to three escrow agents.  It is\n",
      "possible to come with an encoding scheme to match any escrow pattern,\n",
      "for example 3 of 4, such that fewer cooperating escrow agents gives\n",
      "the cracking agency no benefit.\n",
      "\n",
      "--\n",
      "\n",
      "\t\t\t\t\tRobert I. Eachus\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train_news.target[0], train_news.target_names[train_news.target[0]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11, 'sci.crypt')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test_news = fetch_20newsgroups(subset='test', random_state=156, remove=('headers','footers','quotes'))\r\n",
    "X_test = test_news.data\r\n",
    "y_test = test_news.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "len(X_train), len(X_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11314, 7532)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 피쳐 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
    "- Case 1. CountVectorizer + LogisticRegression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "cvect = CountVectorizer()\r\n",
    "cvect.fit(X_train)\r\n",
    "X_train_cv = cvect.transform(X_train)\r\n",
    "X_test_cv = cvect.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "X_train_cv.shape, X_test_cv.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((11314, 101631), (7532, 101631))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=300)\n",
    "lr.fit(X_train_cv, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kimee\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "lr.get_params()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred=lr.predict(X_test_cv)\n",
    "accuracy_score(y_test,pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5962559745087627"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "y_test[:5], pred[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([ 4, 11,  1,  7,  8]), array([ 4, 11,  6,  7,  8]))"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Case 2. TfidVectorizer + LogisticRegression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvect = TfidfVectorizer()\n",
    "tvect.fit(X_train)\n",
    "X_train_tf = tvect.transform(X_train)\n",
    "X_test_tf = tvect.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "X_train_tf.shape, X_test_tf.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((11314, 101631), (7532, 101631))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "lr = LogisticRegression(max_iter=300)\n",
    "lr.fit(X_train_tf, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "pred = lr.predict(X_test_tf)\n",
    "accuracy_score(y_test,pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6736590546999469"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "y_test[:5], pred[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([ 4, 11,  1,  7,  8]), array([5, 1, 1, 7, 8]))"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Case 3. stop_words filtering, ngram_range=(1,2), max_df=300"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "tvect2 = TfidfVectorizer(ngram_range=(1,2), max_df=300, stop_words='english')\n",
    "tvect2.fit(X_train)\n",
    "X_train_tf2 = tvect2.transform(X_train)\n",
    "X_test_tf2 = tvect2.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "X_train_tf2.shape, X_test_tf2.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((11314, 943453), (7532, 943453))"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "lr = LogisticRegression(max_iter=300)\n",
    "lr.fit(X_train_tf2, y_train)\n",
    "pred2 = lr.predict(X_test_tf2)\n",
    "accuracy_score(y_test, pred2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6922464152947424"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Case 4. Case 3에서 LogisticRegression C값을 10으로 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "lr = LogisticRegression(max_iter=300, C=10)\n",
    "lr.fit(X_train_tf2, y_train)\n",
    "pred2 = lr.predict(X_test_tf2)\n",
    "accuracy_score(y_test, pred2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7012745618693574"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline과 GridSearchCV를 통한 하이퍼 파라미터 튜닝"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "from sklearn.pipeline import Pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tvect', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "params = {\n",
    "    'tvect__ngram_range':[(1,1),(1,2)],\n",
    "    'tvect__max_df':[300,700],\n",
    "    'lr__C':[1,10]\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_pipe = GridSearchCV(\n",
    "    pipeline, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "%time grid_pipe.fit(X_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(grid_pipe.best_score_)\n",
    "print(grid_pipe.best_params_)\n",
    "pred = grid_pipe.best_estimator_(X_test)\n",
    "accuracy_score(y_test, pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}